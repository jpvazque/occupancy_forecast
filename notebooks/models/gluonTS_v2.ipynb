{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "armed-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_complete' (DataFrame)\n",
      "Stored 'df_grouped_dates' (DataFrame)\n",
      "Stored 'series_grouped_dates' (Series)\n",
      "Stored 'pandas_dataframe_groupby_site' (DataFrameGroupBy)\n",
      "Stored 'sites_names' (list)\n"
     ]
    }
   ],
   "source": [
    "%run ./imports_models.py\n",
    "%run ./dataset_preparation_v2.ipynb\n",
    "%run -i ./utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-triumph",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "biological-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pandas_dataframe_groupby_site\n",
    "%store -r sites_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-problem",
   "metadata": {},
   "source": [
    "# Prepare Timeseries, Train and Forecast by group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-subsection",
   "metadata": {},
   "source": [
    "* If all_sites is <strong>False</strong>, just one model will be trained with the specific group selected in site_index. \n",
    "* If all_sites is <strong>True</strong>, multiple models will be trained for all groups in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "minus-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = False\n",
    "site_index = 47\n",
    "sites = []\n",
    "\n",
    "if all_sites:\n",
    "    sites = sites_names\n",
    "else:\n",
    "    sites = [sites_names[site_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cloudy-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_info = {'timeseries':[],\n",
    "               'models':[],\n",
    "               'forecasts':[],\n",
    "               'scaler':[]}\n",
    "exec_times_info = {'training_exec_times':[],\n",
    "                   'forecast_exec_times':[]}\n",
    "overall_exec_time = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "expired-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE</th>\n",
       "      <th>DATES</th>\n",
       "      <th>OCCUPANCY_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Product</td>\n",
       "      <td>8/31/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Product</td>\n",
       "      <td>9/1/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Product</td>\n",
       "      <td>9/2/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Product</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Product</td>\n",
       "      <td>9/4/2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>Product</td>\n",
       "      <td>12/7/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>Product</td>\n",
       "      <td>12/8/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>Product</td>\n",
       "      <td>12/9/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>Product</td>\n",
       "      <td>12/10/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>Product</td>\n",
       "      <td>12/11/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SITE       DATES  OCCUPANCY_COUNT\n",
       "48    Product   8/31/2020                0\n",
       "105   Product    9/1/2020                0\n",
       "162   Product    9/2/2020                0\n",
       "219   Product    9/3/2020                0\n",
       "276   Product    9/4/2020                1\n",
       "...       ...         ...              ...\n",
       "4038  Product   12/7/2020                0\n",
       "4095  Product   12/8/2020                0\n",
       "4152  Product   12/9/2020                0\n",
       "4209  Product  12/10/2020                0\n",
       "4266  Product  12/11/2020                0\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataframe_groupby_site.get_group(sites_names[48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "involved-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Training and Forecasting Payroll ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35fa29f05c14b2bb5b51555b7edfbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gluonts.dataset.loader:Multiprocessing is not supported on Windows, num_workers will be set to None.\n",
      "\n",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGroup Payroll\u001b[0m\n",
      "Transform dataset...\n",
      "--- Transforming has ended ---\n",
      "Training model...\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 50/50 [00:01<00:00, 31.87it/s, epoch=1/5, avg_epoch_loss=2.83]\n",
      "\n",
      "100%|██████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.65it/s, epoch=2/5, avg_epoch_loss=1.51]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.86it/s, epoch=3/5, avg_epoch_loss=0.931]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.64it/s, epoch=4/5, avg_epoch_loss=0.727]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 50/50 [00:01<00:00, 37.40it/s, epoch=5/5, avg_epoch_loss=0.414]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training ended at 7.349899053573608 seconds ---\n",
      "Forecasting...\n",
      "--- Forecast ended at 0.01595902442932129 seconds ---\n",
      "\n",
      "Multiple Training and Forecasting ended at--- 7.414998292922974 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Multiple Training and Forecasting %s ...\\n'%sites_names[site_index])\n",
    "\n",
    "start_time_overall = time.time()\n",
    "for site in tqdm(sites):\n",
    "    print('\\033[1m' + 'Group %s'%(site) + '\\033[0m')\n",
    "    site_df = pandas_dataframe_groupby_site.get_group(site)\n",
    "    freq = 'D'\n",
    "    nrows = len(site_df)\n",
    "    site_train_test_timeseries_gluon = prepare_train_test_timeseries_gluon(site_df,\n",
    "                                                                           int(nrows*0.7),\n",
    "                                                                           data_column_name='OCCUPANCY_COUNT', \n",
    "                                                                           date_column_name='DATES', \n",
    "                                                                           freq=freq,\n",
    "                                                                           perform_scale_data=False,\n",
    "                                                                           start_day='8/31/2020')\n",
    "    site_timeseries_gluon_train = site_train_test_timeseries_gluon[0]\n",
    "    site_timeseries_gluon_test = site_train_test_timeseries_gluon[1]\n",
    "    scaler = site_train_test_timeseries_gluon[2]\n",
    "    site_entry_train = next(iter(site_timeseries_gluon_train))\n",
    "    site_entry_test = next(iter(site_timeseries_gluon_test))\n",
    "    site_series_train = to_pandas(site_entry_train)\n",
    "    site_series_test = to_pandas(site_entry_test)\n",
    "    \n",
    "    \n",
    "    print('Transform dataset...')\n",
    "    prediction_length = len(site_series_test) - len(site_series_train)\n",
    "    transformation = create_transformation(freq, 2 * prediction_length, prediction_length)\n",
    "    train_tf = transformation(iter(site_timeseries_gluon_train), is_train=True)\n",
    "    train_tf_entry = next(iter(train_tf))\n",
    "    print(\"--- Transforming has ended ---\")\n",
    "    \n",
    "\n",
    "    print('Training model...')\n",
    "    start_time_training = time.time()\n",
    "    estimator = SimpleFeedForwardEstimator(\n",
    "        num_hidden_dimensions=[10],\n",
    "        prediction_length=prediction_length,\n",
    "        context_length=2*prediction_length,\n",
    "        freq=freq,\n",
    "        trainer=Trainer(ctx=\"cpu\",\n",
    "                        epochs=5,\n",
    "                        learning_rate=1e-3,\n",
    "                        hybridize=False,\n",
    "                        num_batches_per_epoch=50\n",
    "                       )\n",
    "    )\n",
    "    site_predictor = estimator.train(site_timeseries_gluon_train)\n",
    "    training_exec_time = time.time() - start_time_training\n",
    "    print(\"--- Training ended at %s seconds ---\" % (training_exec_time))\n",
    "    \n",
    "    \n",
    "    print('Forecasting...')\n",
    "    start_time_forecast = time.time()\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=site_timeseries_gluon_test,\n",
    "        predictor=site_predictor,\n",
    "        num_samples=100,\n",
    "    )    \n",
    "    site_forecasts = list(forecast_it)\n",
    "    site_tss = list(ts_it)\n",
    "    forecast_exec_time = time.time() - start_time_forecast\n",
    "    print(\"--- Forecast ended at %s seconds ---\\n\" % (forecast_exec_time))    \n",
    "    \n",
    "    exec_times_info['training_exec_times'].append(training_exec_time)\n",
    "    exec_times_info['forecast_exec_times'].append(forecast_exec_time)\n",
    "    \n",
    "    groups_info['timeseries'].append((site_timeseries_gluon_train, site_timeseries_gluon_test))\n",
    "    groups_info['models'].append(site_predictor)\n",
    "    groups_info['forecasts'].append((site_forecasts, site_tss))\n",
    "    groups_info['scaler'].append(scaler)\n",
    "    \n",
    "    \n",
    "overall_exec_time = time.time() - start_time_overall\n",
    "print(\"Multiple Training and Forecasting ended at--- %s seconds ---\" % (overall_exec_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-start",
   "metadata": {},
   "source": [
    "# Load info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "south-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_entry_train = next(iter(groups_info['timeseries'][0][0]))\n",
    "site_entry_test = next(iter(groups_info['timeseries'][0][1]))\n",
    "site_series_train_scaled = to_pandas(site_entry_train)\n",
    "site_series_test_scaled = to_pandas(site_entry_test)\n",
    "forecasts = groups_info['forecasts'][0][0]\n",
    "tss_scaled = groups_info['forecasts'][0][1]\n",
    "forecast_entry = forecasts[0]\n",
    "ts_entry = tss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "pressed-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_series_train = scaler.inverse_transform(site_series_train_scaled.values.reshape(-1,1))\n",
    "# site_series_test = scaler.inverse_transform(site_series_test_scaled.values.reshape(-1,1))\n",
    "# tss = scaler.inverse_transform(tss_scaled[0].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-hurricane",
   "metadata": {},
   "source": [
    "# Forecast evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "certified-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, item in enumerate(forecasts):\n",
    "#     forecasts[i] = np.array(forecasts[i]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "individual-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 81.74it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss_scaled), iter(forecasts), num_series=len(groups_info['timeseries'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "approved-illustration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MSE\": 0.423625489939814,\n",
      "    \"abs_error\": 12.528905868530273,\n",
      "    \"abs_target_sum\": 14.0,\n",
      "    \"abs_target_mean\": 0.6086956521739131,\n",
      "    \"seasonal_error\": 0.49019607843137253,\n",
      "    \"MASE\": 1.1112594770348592,\n",
      "    \"MAPE\": 0.294204654900924,\n",
      "    \"sMAPE\": 1.1237152475055157,\n",
      "    \"OWA\": NaN,\n",
      "    \"MSIS\": 14.58068091351053,\n",
      "    \"QuantileLoss[0.1]\": 6.671433553099631,\n",
      "    \"Coverage[0.1]\": 0.30434782608695654,\n",
      "    \"QuantileLoss[0.5]\": 12.528905387967825,\n",
      "    \"Coverage[0.5]\": 0.5652173913043478,\n",
      "    \"QuantileLoss[0.9]\": 7.35172000080347,\n",
      "    \"Coverage[0.9]\": 0.6956521739130435,\n",
      "    \"RMSE\": 0.6508651856873388,\n",
      "    \"NRMSE\": 1.069278519343485,\n",
      "    \"ND\": 0.8949218477521624,\n",
      "    \"wQuantileLoss[0.1]\": 0.4765309680785451,\n",
      "    \"wQuantileLoss[0.5]\": 0.8949218134262732,\n",
      "    \"wQuantileLoss[0.9]\": 0.5251228572002479,\n",
      "    \"mean_absolute_QuantileLoss\": 8.850686313956976,\n",
      "    \"mean_wQuantileLoss\": 0.6321918795683553,\n",
      "    \"MAE_Coverage\": 0.15797101449275364\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(agg_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "adolescent-denver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>MSE</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>abs_target_sum</th>\n",
       "      <th>abs_target_mean</th>\n",
       "      <th>seasonal_error</th>\n",
       "      <th>MASE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>OWA</th>\n",
       "      <th>MSIS</th>\n",
       "      <th>QuantileLoss[0.1]</th>\n",
       "      <th>Coverage[0.1]</th>\n",
       "      <th>QuantileLoss[0.5]</th>\n",
       "      <th>Coverage[0.5]</th>\n",
       "      <th>QuantileLoss[0.9]</th>\n",
       "      <th>Coverage[0.9]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423625</td>\n",
       "      <td>12.528906</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.111259</td>\n",
       "      <td>0.294205</td>\n",
       "      <td>1.123715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.580681</td>\n",
       "      <td>6.671434</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>12.528905</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>7.35172</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id       MSE  abs_error  abs_target_sum  abs_target_mean  \\\n",
       "0      NaN  0.423625  12.528906            14.0         0.608696   \n",
       "\n",
       "   seasonal_error      MASE      MAPE     sMAPE  OWA       MSIS  \\\n",
       "0        0.490196  1.111259  0.294205  1.123715  NaN  14.580681   \n",
       "\n",
       "   QuantileLoss[0.1]  Coverage[0.1]  QuantileLoss[0.5]  Coverage[0.5]  \\\n",
       "0           6.671434       0.304348          12.528905       0.565217   \n",
       "\n",
       "   QuantileLoss[0.9]  Coverage[0.9]  \n",
       "0            7.35172       0.695652  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-thread",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-diary",
   "metadata": {},
   "source": [
    "#### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\n",
    "\n",
    "site_series_train.plot(ax=ax[0])\n",
    "ax[0].grid(which=\"both\")\n",
    "ax[0].legend([\"train series\"], loc=\"upper left\")\n",
    "\n",
    "site_series_test.plot(ax=ax[1])\n",
    "ax[1].axvline(site_series_train.index[-1], color='r') # end of train dataset\n",
    "ax[1].grid(which=\"both\")\n",
    "ax[1].legend([\"test series\", \"end of train series\"], loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-keeping",
   "metadata": {},
   "source": [
    "### Plot forecasting overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prob_forecasts(ts_entry, forecast_entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
